# 0.2e Explore the kubelet

> The node agent - actually runs your containers

---

## What is the kubelet?

The kubelet is an agent that runs on **every node**. It's the component that actually starts, stops, and monitors containers.

```text
┌─────────────────────────────────────────────────────────────────┐
│                       kubelet                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   API Server says: "Run nginx pod on this node"                 │
│            │                                                    │
│            ▼                                                    │
│   kubelet receives the instruction                              │
│            │                                                    │
│            ▼                                                    │
│   kubelet tells container runtime: "Pull nginx image"           │
│            │                                                    │
│            ▼                                                    │
│   kubelet tells container runtime: "Start the container"        │
│            │                                                    │
│            ▼                                                    │
│   kubelet monitors the container:                               │
│   • Is it running?                                              │
│   • Is it healthy? (liveness/readiness probes)                  │
│   • Reports status back to API Server                           │
│            │                                                    │
│            ▼                                                    │
│   This loop runs every few seconds                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## kubelet vs Other Components

| Component | Where | What It Does |
|-----------|-------|--------------|
| API Server | Control Plane | Receives and stores requests |
| Scheduler | Control Plane | Decides WHERE pods run |
| Controller | Control Plane | Decides WHAT should be running |
| **kubelet** | **Every Node** | **Actually RUNS the containers** |

The kubelet is where "desired state" becomes "actual state"!

---

## Hands-On: Find kubelets

Unlike other control plane components, kubelet runs as a system service, not a pod. But we can still explore it.

```bash
# See nodes (each has a kubelet)
kubectl get nodes

# See kubelet version on each node
kubectl get nodes -o wide
```

The `INTERNAL-IP` and `VERSION` columns show kubelet info.

---

## Hands-On: Check kubelet Status on a Node

```bash
# Exec into a worker node
podman exec -it playground-worker bash

# Check kubelet service status
systemctl status kubelet

# View kubelet logs
journalctl -u kubelet | tail -30

# See kubelet process
ps aux | grep kubelet

# Exit
exit
```

---

## Hands-On: See kubelet's View of Pods

Each kubelet only knows about pods assigned to its node.

```bash
# Create pods that spread across nodes
kubectl create deployment spread-test --image=nginx:alpine --replicas=6

# See where pods landed
kubectl get pods -o wide
```

Now let's see what each kubelet knows:

```bash
# Look at worker node's kubelet
podman exec playground-worker curl -s http://localhost:10250/pods | head -100
```

Note: This might fail due to TLS. Here's another way:

```bash
# From your machine, use kubectl to see pods on a specific node
kubectl get pods -A --field-selector spec.nodeName=playground-worker
```

This shows only pods the kubelet on `playground-worker` is managing!

```bash
kubectl delete deployment spread-test
```

---

## Hands-On: kubelet Pod Lifecycle

Let's trace what kubelet does when starting a pod:

### Step 1: Watch Events Closely

```bash
# Watch events
kubectl get events -w
```

### Step 2: Create a Pod (Another Terminal)

```bash
kubectl run lifecycle-demo --image=nginx:alpine
```

### Step 3: Observe the Sequence

Events show:
```text
Scheduled    pod/lifecycle-demo   Successfully assigned to playground-worker
Pulling      pod/lifecycle-demo   Pulling image "nginx:alpine"
Pulled       pod/lifecycle-demo   Successfully pulled image
Created      pod/lifecycle-demo   Created container nginx
Started      pod/lifecycle-demo   Started container nginx
```

Everything after "Scheduled" is done by kubelet:
1. **Pulling** - kubelet tells container runtime to pull image
2. **Pulled** - Image download complete
3. **Created** - Container created (but not running yet)
4. **Started** - Container is now running

```bash
kubectl delete pod lifecycle-demo
```

---

## Hands-On: Health Checks (kubelet's Job)

kubelet runs health checks to ensure containers are working.

### Liveness Probe - Is the Container Alive?

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: liveness-demo
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "touch /tmp/healthy; sleep 30; rm /tmp/healthy; sleep 600"]
    livenessProbe:
      exec:
        command: ["cat", "/tmp/healthy"]
      initialDelaySeconds: 5
      periodSeconds: 5
EOF

# Watch what happens
kubectl get pod liveness-demo -w
```

The container:
1. Creates `/tmp/healthy` file
2. After 30 seconds, deletes it
3. Liveness probe fails (can't cat the file)
4. **kubelet restarts the container!**

Watch for:
```text
liveness-demo   1/1     Running   0          35s
liveness-demo   1/1     Running   1          70s   # RESTARTED!
```

```bash
# See why
kubectl describe pod liveness-demo | grep -A5 "Liveness"

# See restart count
kubectl get pod liveness-demo

kubectl delete pod liveness-demo
```

### Readiness Probe - Is the Container Ready for Traffic?

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: readiness-demo
spec:
  containers:
  - name: app
    image: nginx:alpine
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5
EOF

# Watch READY column
kubectl get pod readiness-demo -w
```

You'll see:
```text
readiness-demo   0/1     Running   0          2s    # Not ready yet
readiness-demo   1/1     Running   0          8s    # Probe passed!
```

kubelet runs the HTTP probe and marks the pod ready when it succeeds.

```bash
kubectl delete pod readiness-demo
```

---

## Hands-On: kubelet Resource Management

kubelet enforces resource limits on containers.

### Step 1: Create a Pod with Limits

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
EOF
```

### Step 2: Check kubelet Enforcement

```bash
# See the resource settings
kubectl describe pod resource-demo | grep -A6 "Limits"

# Check container's cgroup limits (inside the node)
podman exec playground-worker bash -c '
  CONTAINER_ID=$(crictl ps --name resource-demo -q)
  crictl inspect $CONTAINER_ID | grep -A10 "linux"
'
```

kubelet creates cgroups to enforce these limits!

```bash
kubectl delete pod resource-demo
```

---

## Hands-On: Static Pods (kubelet's Special Feature)

kubelet can run "static pods" from local files, without the API Server!

This is how the control plane components themselves run.

```bash
# See static pod manifest directory on control-plane
podman exec playground-control-plane ls /etc/kubernetes/manifests/
```

Output:
```text
etcd.yaml
kube-apiserver.yaml
kube-controller-manager.yaml
kube-scheduler.yaml
```

These are static pods! kubelet watches this directory and starts anything it finds there.

### Create Your Own Static Pod

```bash
# Create a static pod manifest on worker node
podman exec playground-worker bash -c '
cat > /etc/kubernetes/manifests/static-demo.yaml << EOF
apiVersion: v1
kind: Pod
metadata:
  name: static-demo
  namespace: default
spec:
  containers:
  - name: nginx
    image: nginx:alpine
EOF
'

# Wait a moment, then check
kubectl get pods
```

You should see `static-demo-playground-worker` appear!

This pod:
- Was NOT created via API Server
- kubelet found the file and started it
- kubelet mirrors it to API Server so kubectl can see it

```bash
# Try to delete it
kubectl delete pod static-demo-playground-worker

# Check again
kubectl get pods
# It comes back! kubelet recreates it from the file!

# To really delete it, remove the file
podman exec playground-worker rm /etc/kubernetes/manifests/static-demo.yaml

# Now it's gone
kubectl get pods
```

---

## Hands-On: kubelet Logs for Troubleshooting

When pods fail to start, kubelet logs tell you why:

```bash
# View kubelet logs on a worker
podman exec playground-worker journalctl -u kubelet --since "5 minutes ago"

# Look for errors
podman exec playground-worker journalctl -u kubelet | grep -i error | tail -20
```

---

## Hands-On: Node Conditions (kubelet Reports These)

kubelet reports node health to the control plane:

```bash
kubectl describe node playground-worker | grep -A15 "Conditions:"
```

Output:
```text
Conditions:
  Type                 Status
  Ready                True
  MemoryPressure       False
  DiskPressure         False
  PIDPressure          False
  NetworkUnavailable   False
```

kubelet monitors:
- **Ready** - Is the node working?
- **MemoryPressure** - Running low on RAM?
- **DiskPressure** - Running low on disk?
- **PIDPressure** - Too many processes?

If any condition becomes bad, kubelet reports it, and controllers may evict pods!

---

## Experiment: What If kubelet Stops?

```bash
# Create a pod on a worker
kubectl run kubelet-test --image=nginx:alpine --overrides='{"spec":{"nodeName":"playground-worker"}}'

# Stop kubelet on that worker
podman exec playground-worker systemctl stop kubelet

# Check node status (wait ~40 seconds)
kubectl get nodes -w
```

You'll see:
```text
playground-worker   NotReady   ...
```

The node goes NotReady because kubelet stopped reporting!

The pod continues running (container runtime doesn't stop), but Kubernetes can't manage it.

```bash
# Restart kubelet
podman exec playground-worker systemctl start kubelet

# Node recovers
kubectl get nodes

kubectl delete pod kubelet-test
```

---

## Key Takeaways

1. **kubelet runs on every node** - It's the "hands" that do the work
2. **Starts containers** - Works with container runtime (containerd)
3. **Runs health checks** - Liveness/readiness probes
4. **Enforces resources** - CPU/memory limits via cgroups
5. **Reports status** - Tells control plane about node and pod health
6. **Static pods** - Can run pods without API Server (bootstrapping)
7. **Not a pod itself** - Runs as a system service

---

## Quick Reference

```bash
# See nodes (each has kubelet)
kubectl get nodes -o wide

# See pods on specific node
kubectl get pods -A --field-selector spec.nodeName=<node-name>

# Check node conditions (kubelet reports these)
kubectl describe node <node-name> | grep -A10 Conditions

# Exec into node and check kubelet
podman exec -it <node-name> bash
systemctl status kubelet
journalctl -u kubelet | tail -50

# Static pod directory
/etc/kubernetes/manifests/

# Liveness/readiness probe syntax
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 10
```

---

**Next:** [0.2f Explore Pods](./0.2f_explore_pods.md)
